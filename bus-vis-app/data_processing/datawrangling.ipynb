{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling routes and charging stations\n",
    "### *Assumes data is in a folder called RAWDATA in same folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------\n",
    "TABULAR DATA-SPECIFIC INFORMATION FOR: 1-B. BusRoutes_UTA.dbf\n",
    "-----------------------------------------\n",
    "\n",
    "\n",
    "1. Number of variables:\n",
    "5\n",
    "\n",
    "2. Number of cases/rows: \n",
    "114\n",
    "\n",
    "3. Variable List\n",
    "    A. Name: LineAbbr\n",
    "       Description: Abbreviations for bus lines.\n",
    "\tNominal \n",
    "                    \n",
    "    B. Name: LineName\n",
    "       Description: Names of bus lines.\n",
    "\tNominal\n",
    "\n",
    "    C. Name: Service\n",
    "       Description: Category of service of bus lines.\n",
    "\tNominal, including local, express, BRT, fast bus, shuttle, ski, flex.\n",
    "\n",
    "    D. Name: Frequency\n",
    "       Description: Frequency of bus lines.\n",
    "\tRatio\n",
    "\n",
    "    E. Name: Shape_Leng\n",
    "       Description: Length of the bus routes.\n",
    "\tRatio, unit: foot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read routes info and add to array -old\n",
    "from dbfread import DBF\n",
    "i = 0\n",
    "routes = []\n",
    "for record in DBF('RAWDATA\\\\1. Network Data\\\\1. BusRoutes_UTA\\\\BusRoutes_UTA.dbf'):\n",
    "    i += 1\n",
    "    routes.append({'lineAbbr': record['LineAbbr'], 'lineName': record[\"LineName\"], 'service': record[\"Service\"], 'shape_length': record[\"Shape_Leng\"], 'busses': set()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#better file that has coordinates too\n",
    "data = json.load(open(\"RAWDATA\\\\1. Network Data\\\\1. BusRoutes_UTA\\\\BusRoutes_UTA.json\"))\n",
    "routes = []\n",
    "for r in data['features']:\n",
    "    record = r[\"properties\"]\n",
    "    routes.append(\n",
    "        {  \n",
    "            'lineAbbr': record['LineAbbr'], \n",
    "            'lineName': record[\"LineName\"], \n",
    "            'service': record[\"Service\"], \n",
    "            'shape_length': record[\"Shape_Leng\"], \n",
    "            'busses': set(),\n",
    "            'coordinates': r['geometry']['coordinates']\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc path length\n",
    "import math\n",
    "for r in routes:\n",
    "    for i in range(len(r['coordinates'])):\n",
    "        sumdist = 0\n",
    "        #calc dist between points \n",
    "        dist0 = r['coordinates'][i][0][0] - r['coordinates'][i - 1][0][0]\n",
    "        dist1 = r['coordinates'][i][0][1] - r['coordinates'][i - 1][0][1]\n",
    "\n",
    "        dist0 = r['coordinates'][i - 1][0][0] - r['coordinates'][i][0][0]\n",
    "        dist1 = r['coordinates'][i - 1][0][1] - r['coordinates'][i][0][1]\n",
    "        #sum of total distance\n",
    "        sumdist += math.sqrt(dist0 * dist0 + dist1 * dist1)\n",
    "    r['path_length'] = sumdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007600350806313509\n"
     ]
    }
   ],
   "source": [
    "print(routes[0]['path_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import list of busses from runcut\n",
    "import openpyxl\n",
    "\n",
    "wb_obj = openpyxl.load_workbook(\"RAWDATA\\\\1. Network Data\\\\3. UTA Runcut File  Aug2016.xlsx\")\n",
    "sheet = wb_obj.active\n",
    "\n",
    "i = 0\n",
    "for row in sheet.iter_rows():\n",
    "    i += 1\n",
    "    if i == 1:\n",
    "        continue\n",
    "    for route in routes:\n",
    "        if route['lineAbbr'] == row[0].value:\n",
    "            route['busses'].add(row[3].value)\n",
    "    # if row[0].value in routes:\n",
    "    #     routes[row[0].value][\"busses\"].add(row[3].value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write it to allRoutes.json\n",
    "import json\n",
    "def set_default(obj):\n",
    "    if isinstance(obj, set):\n",
    "        return list(obj)\n",
    "    raise TypeError\n",
    "\n",
    "with open('allRoutes.json', 'w') as outfile:\n",
    "    json.dump(routes, outfile, default=set_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------\n",
    "TABULAR DATA-SPECIFIC INFORMATION FOR: 2-B. BusStops_UTA.dbf\n",
    "-----------------------------------------\n",
    "\n",
    "\n",
    "1. Number of variables:\n",
    "4\n",
    "\n",
    "2. Number of cases/rows: \n",
    "5987\n",
    "\n",
    "3. Variable List\n",
    "    A. Name: StopId\n",
    "       Description: Unique identifier for bus stops.\n",
    "\tNominal \n",
    "                    \n",
    "    B. Name: StopName\n",
    "       Description: The comlete names of bus stops.\n",
    "\tNominal\n",
    "\n",
    "    C. Name: StreetNum\n",
    "       Description: The number of the streets the stops are on.\n",
    "\tNominal\n",
    "\n",
    "    D. Name: OnStreet\n",
    "       Description: The name of the streets the stops are on.\n",
    "\tNominal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in stops info from dbf file\n",
    "stops = []\n",
    "for record in DBF('RAWDATA\\\\1. Network Data\\\\2. BusStops_UTA\\\\BusStops_UTA.dbf'):\n",
    "    stops.append({\n",
    "        'StopId' : record['StopId'],\n",
    "        'StopName': record[\"StopName\"],\n",
    "        'StreetNum': record[\"StreetNum\"],\n",
    "        'OnStreet': record[\"OnStreet\"],\n",
    "        'AtStreet': record[\"AtStreet\"],\n",
    "        'City': record[\"City\"],\n",
    "        'InService': record[\"InService\"],\n",
    "        'Bench': record[\"Bench\"],\n",
    "        'Shelter': record[\"Shelter\"],\n",
    "        'Lighting': record[\"Lighting\"],\n",
    "        'Garbage': record[\"Garbage\"],\n",
    "        'Bicycle': record[\"Bicycle\"],\n",
    "        'Transfer': record[\"Transfer\"],\n",
    "        'LocationUs': record[\"LocationUs\"],\n",
    "        'UTAStopID': record[\"UTAStopID\"],\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5987\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# better file that has properties and coordinates\n",
    "stops = []\n",
    "data = json.load(open(\"RAWDATA\\\\1. Network Data\\\\2. BusStops_UTA\\BusStops_UTA.json\"))\n",
    "i = 0\n",
    "for record in data[\"features\"]:\n",
    "    props = record[\"properties\"]\n",
    "    stops.append({\n",
    "        'stopId' : props['StopId'],\n",
    "        'stopName': props[\"StopName\"],\n",
    "        'streetNum': props[\"StreetNum\"],\n",
    "        'onStreet': props[\"OnStreet\"],\n",
    "        'atStreet': props[\"AtStreet\"],\n",
    "        'city': props[\"City\"],\n",
    "        'inService': props[\"InService\"],\n",
    "        'bench': props[\"Bench\"],\n",
    "        'shelter': props[\"Shelter\"],\n",
    "        'lighting': props[\"Lighting\"],\n",
    "        'garbage': props[\"Garbage\"],\n",
    "        'bicycle': props[\"Bicycle\"],\n",
    "        'transfer': props[\"Transfer\"],\n",
    "        'locationUs': props[\"LocationUs\"],\n",
    "        'UTAStopID': props[\"UTAStopID\"],\n",
    "\n",
    "        'coordinates': record['geometry']['coordinates']\n",
    "    })\n",
    "print(len(stops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to allStops\n",
    "with open('allStops.json', 'w') as outfile:\n",
    "    json.dump(stops, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't think I did anything below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = 'p180'\n",
    "data = json.load(open(\"DATA\\\\plans\\\\\" + plan + \".json\"))\n",
    "stops = json.load(open(\"allStopsNew.json\"))\n",
    "finalFile = \"DATA\\\\stationLocations\\\\\" + plan + \".json\"\n",
    "statLocs = {'type': 'FeatureCollection', 'features': []}\n",
    "for cs in data['charging_stations']:\n",
    "    coords = []\n",
    "    # find allstopps where name matches\n",
    "    for s in stops:\n",
    "        if s[\"stopName\"].replace(\" \", \"\") == cs[\"stop_name\"].replace(\" \", \"\"):\n",
    "            coords = s[\"coordinates\"]\n",
    "    if coords == []:\n",
    "        print(\"NO COORDS\", cs)\n",
    "    geo = {'type': 'Point', 'coordinates': coords}\n",
    "    ob = {'type': 'Feature', 'geometry': geo, 'properties': cs}\n",
    "    statLocs['features'].append(ob)\n",
    "\n",
    "with open(finalFile, 'w') as outfile:\n",
    "    json.dump(statLocs, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "t = datetime.time(1, 2, 3)\n",
    "\n",
    "plan = \"p20\"\n",
    "stations = {}\n",
    "dataBuses = json.load(open(\"DATA\\\\buses\\\\\" + plan + \".json\"))\n",
    "# dataStations = json.load(open(\"DATA\\\\plans\\\\\" + plan + \".json\"))['charging_stations']\n",
    "dataStations = json.load(open(\"allStopsNew.json\"))\n",
    "\n",
    "# for station in dataStations:\n",
    "#     stations[station['stopName']] = {'stop_id': station['stopId'], 'stop_name': station['stopName'], 'busTimes': {}}\n",
    "for i in range(24):\n",
    "    timeStr = str(i) + \":00\"\n",
    "    time = datetime.time(i)\n",
    "    for bus in dataBuses['buses']:\n",
    "        for stp in bus['stops']:\n",
    "            arvtime = datetime.time(0) if (stp['arrival_time'] == '') else datetime.time(int(stp['arrival_time'].split(\":\")[0]), int(stp['arrival_time'].split(\":\")[1]))\n",
    "            deptime = datetime.time(23,59) if (stp['departure_time'] == '') else datetime.time(int(stp['departure_time'].split(\":\")[0]), int(stp['departure_time'].split(\":\")[1]))\n",
    "            if arvtime <= time and time <= deptime: #at stop\n",
    "                if stp['stop_name'] not in stations:\n",
    "                    stations[stp['stop_name']] = {'stop_id': station['stopId'], 'stop_name': station['stopName'], 'busTimes': {}}\n",
    "                if timeStr not in stations[stp['stop_name']]['busTimes']:\n",
    "                    stations[stp['stop_name']]['busTimes'][timeStr] = []\n",
    "                stations[stp['stop_name']]['busTimes'][timeStr].append(bus['id'])\n",
    "\n",
    "with open('busesAtStations', 'w') as outfile:\n",
    "    json.dump(stations, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stop_id': 24302, 'stop_name': 'WASATCH BLVD @ 8551 S', 'busTimes': {'0:00': ['2049', '2001', '2002', '2011', '2012', '2017', '2021', '2027', '2030', '2037', '2045', '2047'], '1:00': ['2049', '2001', '2002', '2011', '2012', '2017', '2021', '2027', '2030', '2037', '2045', '2047'], '2:00': ['2049', '2001', '2002', '2011', '2012', '2017', '2021', '2027', '2030', '2037', '2045', '2047'], '3:00': ['2049', '2001', '2002', '2011', '2012', '2017', '2021', '2027', '2030', '2037', '2045', '2047'], '4:00': ['2049', '2001', '2002', '2011', '2012', '2017', '2021', '2027', '2030', '2037', '2045', '2047'], '5:00': ['2049', '2002', '2011', '2012', '2017', '2021', '2027', '2030', '2037', '2045', '2047'], '6:00': ['2049', '2000', '2006', '2027', '2030', '2037', '2045', '2047'], '7:00': ['2049', '2016', '2028', '2045', '2047'], '8:00': ['2049', '2001', '2013'], '9:00': ['2049', '2012', '2021'], '10:00': ['2049', '2016', '2018'], '11:00': ['2049', '2001', '2038'], '12:00': ['2049', '2002', '2021'], '13:00': ['2006', '2014', '2016'], '14:00': ['2001', '2028', '2034'], '15:00': ['2049', '2006', '2021'], '16:00': ['2014', '2016', '2028'], '17:00': ['2001', '2006'], '18:00': ['2021', '2028', '2046'], '19:00': ['2006', '2016', '2022', '2030', '2031'], '20:00': ['2056', '2016', '2022', '2028', '2030', '2031', '2047'], '21:00': ['2056', '2006', '2014', '2016', '2022', '2030', '2031', '2033', '2039', '2047'], '22:00': ['2056', '2016', '2022', '2028', '2030', '2031', '2033', '2039', '2047'], '23:00': ['2056', '2006', '2008', '2016', '2022', '2030', '2031', '2033', '2039', '2047']}}\n"
     ]
    }
   ],
   "source": [
    "# Stations\n",
    "# [stationName : {'stop_id': x, 'stop_name': y, 'busTimes': {'0:00': [1,2,3], '1:00': [4,5,6] ... '23:00': [2,5,6]}}]\n",
    "print(stations['FREEDOM BLVD @ 610 S'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ca4ed7e0411efdd55c86abb9501ed3ebc25f575cccb7f83736f13ee17cb9622"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
